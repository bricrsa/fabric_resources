{"cells":[{"cell_type":"markdown","source":["Prerequisites:\n","\n","- Target workspace and Lakehouse must exist\n","- Tested on PySpark and Python kernels\n","- Note: target lakehouse must exist!"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"37e8a1ae-8aa3-402e-bafd-99b0ea2889e6"},{"cell_type":"code","source":["%pip install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"jupyter":{"outputs_hidden":true}},"id":"dfb6bb72-f9b4-4e8a-9b8a-cd06ef31ed57"},{"cell_type":"code","source":["# Original Author Nalaka, modified Brett Cooper\n","# modified from https://bidiaries.com/simplify-shortcuts-bulk-creation-with-pyspark-semantic-link-labs-in-microsoft-fabric#heading-scenario-2-bulk-shortcut-creation-from-existing-source-tables\n","\n","import sempy_labs\n","from datetime import datetime\n","\n","# Parameters for source and destination lakehouse and Workspaces\n","source_lakehouse = \"SOURCE_LAKEHOUSE_NAME\"\n","source_workspace = \"SOURCE_WORKSPACE_NAME\"\n","destination_lakehouse = \"TARGET_LAKEHOSUE_NAME\" # note: target lakehouse must exist!\n","destination_workspace = \"TARGET_WORKSPACE_NAME\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"dee2b865-cb90-4d55-a2b8-0370381c60c0"},{"cell_type":"code","source":["# Fetch the list of tables from the source lakehouse\n","# reminder that the target lakehouse needs to exist\n","# This is done once and reused to improve perf, do not rerun cells below without refreshing this list\n","tables = sempy_labs.lakehouse.get_lakehouse_tables(\n","    lakehouse=source_lakehouse,\n","    workspace=source_workspace\n",")\n","\n","# to filter just based on a specific schema\n","# tables = tables[tables['Schema Name'] == 'finance']\n","\n","tables_in_destination = sempy_labs.lakehouse.get_lakehouse_tables(\n","    lakehouse=destination_lakehouse,\n","    workspace=destination_workspace\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"14716198-fb71-48a8-8f01-ce5eef3fc5eb"},{"cell_type":"code","source":["# check the content to be worked on\n","# tables"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"abbf6c68-45c7-40f5-be71-24decbb7b05b"},{"cell_type":"code","source":["# Function to check for existing shortcuts\n","def shortcut_exists(destination_lakehouse, destination_workspace, shortcut_name, schema_name):\n","    exists = ((tables_in_destination['Schema Name'] == schema_name) & \n","            (tables_in_destination['Table Name'] == shortcut_name)).any()\n","            \n","    return exists"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"f28c86f6-5d26-4dab-8f30-c621b92a274a"},{"cell_type":"code","source":["#what to do if the target shortcut already exists\n","# 'Replace' or 'Skip' \n","shortcut_duplicate_behaviour = 'Skip'  # Replace - tries to delete and recreate the sc, or 'Skip' - or any_other_string this gives the same behaviour as Abort as in the documentation from sem link labs"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"94ac5377-6e90-4281-a6cd-c155521831ec"},{"cell_type":"code","source":["# Iterate through each row in the DataFrame to process the 'Table Name'\n","for _, row in tables.iterrows():\n","    shortcut_name = row['Table Name']  # Extract 'Table Name' column as shortcut name\n","    schema_name = row['Schema Name']\n","    source_path = f\"Tables/{schema_name}\"\n","    destination_path = f\"Tables/{schema_name}\"\n","    \n","    # Skip processing for shortcut_name 'schema.json.gz'\n","    if shortcut_name == 'schema.json.gz':\n","        continue\n","    \n","    print(f\"\\n âˆŸ {datetime.now().strftime('%H:%M:%S')} Processing shortcut: {shortcut_name} in schema {schema_name}\")\n","\n","\n","    # Check if the shortcut already exists\n","    if shortcut_exists(destination_lakehouse, destination_workspace, shortcut_name, schema_name) and shortcut_duplicate_behaviour == 'Replace':\n","            try:\n","                # Delete the existing shortcut\n","                sempy_labs.lakehouse.delete_shortcut(\n","                        shortcut_name=shortcut_name,\n","                        lakehouse=destination_lakehouse,\n","                        workspace=destination_workspace,\n","                        shortcut_path=destination_path\n","                    )\n","            except Exception as e:\n","                print(f\"ðŸ”´ Failed to delete existing shortcut '{shortcut_name}'. Error: {e}\")\n","                continue  # Skip to the next shortcut if delete fails\n","    elif shortcut_exists(destination_lakehouse, destination_workspace, shortcut_name, schema_name):\n","        print(f\"ðŸ”µ The shortcut named {shortcut_name} in schema {schema_name} in lakehouse {destination_workspace} has been skipped, already exists.\")\n","        continue\n","    # Create a new shortcut\n","    \n","    try:\n","        sempy_labs.lakehouse.create_shortcut_onelake(\n","            table_name=shortcut_name, source_lakehouse=source_lakehouse, source_workspace=source_workspace, source_path=source_path, \n","            destination_lakehouse=destination_lakehouse,destination_workspace=destination_workspace, destination_path=destination_path\n","            )\n","    except Exception as e:\n","        print(f\"ðŸ”´ Failed to create shortcut for '{shortcut_name}'. Error: {e}\")\n","\n","print(\"\\n\\n âˆŸ ðŸŸ¢ðŸŸ¢ðŸŸ¢ All shortcuts processed successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"7ab8f3f6-cbb0-42b8-a859-d8de67f3f961"},{"cell_type":"markdown","source":["### Delete the target lakehouse shortcuts - for testing"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c38e3116-99df-4a4c-a839-9c8fd4bdb1eb"},{"cell_type":"code","source":["# refresh the tables list\n","tables_in_destination = sempy_labs.lakehouse.get_lakehouse_tables(\n","    lakehouse=destination_lakehouse,\n","    workspace=destination_workspace\n",")\n","print(f\"\\n âˆŸ {datetime.now().strftime('%H:%M:%S')} Deleteing shortcuts\")\n","# Iterate through each row in the DataFrame to process the 'Table Name'\n","for _, row in tables_in_destination.iterrows():\n","    shortcut_name = row['Table Name']  # Extract 'Table Name' column as shortcut name\n","    schema_name = row['Schema Name']\n","    destination_path = f\"Tables/{schema_name}\"       \n","    # Delete the existing shortcut\n","    sempy_labs.lakehouse.delete_shortcut(\n","            shortcut_name=shortcut_name,\n","            lakehouse=destination_lakehouse,\n","            workspace=destination_workspace,\n","            shortcut_path=destination_path)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"editable":false,"run_control":{"frozen":true}},"id":"835b5868-9d1f-495e-9dff-3a7e958144b5"}],"metadata":{"kernel_info":{"name":"jupyter","jupyter_kernel_name":"python3.11"},"kernelspec":{"name":"jupyter","display_name":"Jupyter"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"jupyter_python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}